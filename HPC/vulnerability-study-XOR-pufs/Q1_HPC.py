import binascii
import json
import time
from pyspark.sql import SparkSession
import numpy as np
from pyspark.sql.types import StringType
from pyspark.sql.functions import col
from pyspark.sql.types import DoubleType
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.regression import RandomForestRegressor
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml import Pipeline
from pyspark.ml.classification import MultilayerPerceptronClassifier
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml.feature import Binarizer
from pyspark.sql.functions import when



spark = SparkSession.builder \
	.appName("COM6012 Spark Intro") \
	.config("spark.local.dir","/fastdata/acr21mp") \
	.getOrCreate()

sc = spark.sparkContext
spark.conf.set("spark.sql.execution.arrow.pyspark.enabled", "true")
sc.setLogLevel("WARN")
rawdata_train = spark.read.csv('../Data/XOR_Arbiter_PUFs/5xor_128bit/train_5xor_128dim.csv')
rawdata_test = spark.read.csv('../Data/XOR_Arbiter_PUFs/5xor_128bit/test_5xor_128dim.csv')
rawdata_train.cache()
rawdata_test.cache()
ncolumns = len(rawdata_train.columns)

#renaming the last column containing response as labels.
rawdata_train = rawdata_train.withColumnRenamed('_c128', 'labels') 
rawdata_test = rawdata_test.withColumnRenamed('_c128', 'labels') 
#rawdata_train.printSchema()
#rawdata_test.printSchema()

#get all the column names
StringColumns = [x.name for x in rawdata_train.schema.fields if x.dataType == StringType()]


#cast all the column data to double type
for c in StringColumns:
    rawdata_train = rawdata_train.withColumn(c, col(c).cast("double"))

for c in StringColumns:	
	rawdata_test = rawdata_test.withColumn(c, col(c).cast("double"))

rawdata_train.printSchema()

# The response are of the form (-1,1), for which i have mapped -1 to 0 to make it (0,1).
rawdata_train = rawdata_train.withColumn("labels", when(rawdata_train.labels == 1.0,1.0) \
      .when(rawdata_train.labels == -1.0,0.0) \
      .otherwise(rawdata_train.labels))

rawdata_test = rawdata_test.withColumn("labels", when(rawdata_test.labels == 1.0,1.0) \
      .when(rawdata_test.labels == -1.0,0.0) \
      .otherwise(rawdata_test.labels))

#binarizer = Binarizer(threshold=0.5, inputCol="labels", outputCol="binary_labels")

#rawdata_new = binarizer.transfrom(rawdata)

#print('training data has -',rawdata.count())

#Split the testing data and training data to get 1% of the whole data
print('\n')
small_rawdata_train,_ = rawdata_train.randomSplit([0.01,0.99],1242)
small_rawdata_training,small_rawdata_test = small_rawdata_train.randomSplit([0.7,0.3],1242)
#print('1% of training data has -',small_rawdata.cache().count())

small_rawdata_training.show(5) 
#small_rawdata_test.show(5)
#Save 1% data so it can be read later
small_rawdata_training.write.mode("overwrite").parquet('../Data/small_rawdata_train.parquet')
#small_rawdata_test.write.mode("overwrite").parquet('../Data/small_rawdata_test.parquet')
#small_rawdata_train,small_rawdata_test = small_rawdata.randomSplit([0.7,0.3],1242)

print('1% of training data has -',small_rawdata_training.cache().count())
#print('1% of test data has -',small_rawdata_test.cache().count())

vecAssembler = VectorAssembler(inputCols=StringColumns[:-1], outputCol="features")
vecTrainingData = vecAssembler.transform(small_rawdata_training)
print('Vectorized training data -')
vecTrainingData.select("features", "labels").show(5)

rf = RandomForestClassifier(labelCol="labels", featuresCol="features", maxDepth=5, numTrees=3, \
                           featureSubsetStrategy = 'auto', seed=1242, bootstrap=False)
stagesrf = [vecAssembler, rf]
pipelinerf = Pipeline(stages=stagesrf)

paramGrid = ParamGridBuilder() \
    .addGrid(rf.maxDepth, [1, 5, 10]) \
    .addGrid(rf.maxBins, [2, 10, 20]) \
    .addGrid(rf.numTrees, [1, 5, 10]) \
    .build()

evaluator = MulticlassClassificationEvaluator\
      (labelCol="labels", predictionCol="prediction", metricName="accuracy")

crossval = CrossValidator(estimator=pipelinerf,
                          estimatorParamMaps=paramGrid,
                          evaluator=evaluator,
                          numFolds=5)
start = time.time()
cvModel_rf = crossval.fit(small_rawdata_training)
stop = time.time()
tuning_RF_training_time=stop - start
print(f"Hyper parameter tuning - RF model training time : {stop-start}s")
start = time.time()
prediction = cvModel_rf.transform(rawdata_test)
accuracy = evaluator.evaluate(prediction)
stop = time.time()
tuning_RF_testing_time=stop - start
print(f"Hyper parameter tuning - RF model testing time: {stop - start}s")


print("Accuracy for best rf model = %g " % accuracy)
print("Best Hyper parameters for random forest model are :")
# .bestModel() returns the model object in the crossvalidator. This object is a pipeline
# .stages[-1] returns the last stage in the pipeline, which for our case is our classifier
# .extractParamMap() returns a map with the parameters, which we turn into a dictionary 
paramDict_RF = {param[0].name: param[1] for param in cvModel_rf.bestModel.stages[-1].extractParamMap().items()}
# Here, we're converting the dictionary to a JSON object to make it easy to print. You can print it however you'd like
print(json.dumps(paramDict_RF, indent = 4))


lr = LogisticRegression(featuresCol='features', labelCol='labels', family='binomial')
stageslr = [vecAssembler, lr]
pipelinelr = Pipeline(stages=stageslr)

#use grid builder for hyper parameter tuning 
# i have selected elasticNetParam values as 0.0 for L2 and 1.0 for L1 and 0.5 for elastic Net LR.

paramGrid = ParamGridBuilder() \
    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \
    .addGrid(lr.regParam, [0.001, 0.01, 0.1]) \
    .addGrid(lr.maxIter, [75, 150, 300]) \
    .build()


evaluator = MulticlassClassificationEvaluator\
      (labelCol="labels", predictionCol="prediction", metricName="accuracy")

crossval = CrossValidator(estimator=pipelinelr,
                          estimatorParamMaps=paramGrid,
                          evaluator=evaluator,
                          numFolds=5)

start = time.time()
cvModel_lr = crossval.fit(small_rawdata_training)
stop = time.time()
tuning_LR_training_time=stop - start
print(f"Hyper parameter tuning - LR model training time : {stop-start}s")
start = time.time()
prediction = cvModel_lr.transform(rawdata_test)
accuracy = evaluator.evaluate(prediction)
stop = time.time()
tuning_LR_testing_time=stop - start
print(f"Hyper parameter tuning - LR model testing time : {stop-start}s")



print("Accuracy for best log regress model = %g " % accuracy)
print("Best Hyper parameters for logistic regression model are :")
paramDict_LR = {param[0].name: param[1] for param in cvModel_lr.bestModel.stages[-1].extractParamMap().items()}
# Here, we're converting the dictionary to a JSON object to make it easy to print. You can print it however you'd like
print(json.dumps(paramDict_LR, indent = 4))


#Shallow Neural networks

# The first element HAS to be equal to the number of input features
layers = [ncolumns-1, 20, 5, 2] 
mpc = MultilayerPerceptronClassifier(labelCol="labels", featuresCol="features", maxIter=100, blockSize=256, layers=layers, seed=1500)

stagesmpc = [vecAssembler, mpc]
pipelinempc = Pipeline(stages=stagesmpc)

layers_list = [[ncolumns-1, 20, 5, 2],[ncolumns-1, 20, 2],[ncolumns-1, 20, 40, 2]]
paramGrid = ParamGridBuilder() \
    .addGrid(mpc.layers, layers_list) \
    .addGrid(mpc.stepSize, [0.001, 0.01, 0.1]) \
    .addGrid(mpc.maxIter, [75, 150, 300]) \
    .build()

evaluator = MulticlassClassificationEvaluator\
      (labelCol="labels", predictionCol="prediction", metricName="accuracy")

crossval = CrossValidator(estimator=pipelinempc,
                          estimatorParamMaps=paramGrid,
                          evaluator=evaluator,
                          numFolds=5)

start = time.time()
cvModel_nn = crossval.fit(small_rawdata_training)
stop = time.time()
tuning_NN_training_time=stop - start
print(f"Hyper parameter tuning - NN model training time : {stop-start}s")
start = time.time()
prediction = cvModel_nn.transform(rawdata_test)
accuracy = evaluator.evaluate(prediction)
stop = time.time()
tuning_NN_training_time=stop - start
print(f"Hyper parameter tuning - NN model testing time : {stop-start}s")

print("Accuracy for best Shallow NN model = %g " % accuracy)
print("Best Hyper parameters for Shallow NN model are :")
paramDict_NN = {param[0].name: param[1] for param in cvModel_nn.bestModel.stages[-1].extractParamMap().items()}
# Here, we're converting the dictionary to a JSON object to make it easy to print. You can print it however you'd like
print(json.dumps(paramDict_NN, indent = 4))




#Now train full data using the best hyperparameters obtained
# Random Forest Model
evaluatorROC = BinaryClassificationEvaluator\
     (labelCol="labels", rawPredictionCol="prediction", metricName="areaUnderROC")

start = time.time()
RFModel = pipelinerf.fit(rawdata_train,cvModel_rf.bestModel.stages[-1].extractParamMap())
stop = time.time()
RF_training_time=stop - start
print(f"Training time RF: {stop - start}s")
start = time.time()
prediction = RFModel.transform(rawdata_test)
stop = time.time()
RF_testing_time=stop - start
print(f"Testing time RF: {stop - start}s")
accuracy = evaluator.evaluate(prediction)
ROC = evaluatorROC.evaluate(prediction)


print("Accuracy for fully trained rf model = %g " % accuracy)
print("Area under ROC for RF model = %g" % ROC)


#Logistic Regression Model
start = time.time()
LRModel = pipelinelr.fit(rawdata_train,cvModel_lr.bestModel.stages[-1].extractParamMap())
stop = time.time()
LR_training_time=stop - start
print(f"Training time LR: {(stop - start)}s")
start = time.time()
prediction = LRModel.transform(rawdata_test)
stop = time.time()
LR_testing_time=stop - start
print(f"Testing time LR: {stop - start}s")
accuracy = evaluator.evaluate(prediction)
ROC = evaluatorROC.evaluate(prediction)


print("Accuracy for fully trained LR model = %g " % accuracy)
print("Area under ROC for LR model = %g" % ROC)


#Neural Network Model
start = time.time()
NNModel = pipelinempc.fit(rawdata_train,cvModel_nn.bestModel.stages[-1].extractParamMap())
stop = time.time()
NN_training_time=stop - start
print(f"Training time NN: {stop - start}s")

start = time.time()
prediction = NNModel.transform(rawdata_test)
stop = time.time()
NN_testing_time=stop - start
print(f"Testing time NN: {stop - start}s")
accuracy = evaluator.evaluate(prediction)
ROC = evaluatorROC.evaluate(prediction)



print("Accuracy for fully trained NN model = %g " % accuracy)
print("Area under ROC for NN model = %g" % ROC)



